<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Tianxing Wu</title>

    <meta name="author" content="Tianxing Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto">
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:65%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Tianxing Wu
                </p>
                <p>
                  I am a PhD student at <a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>, <a href="https://www.ntu.edu.sg">Nanyang Technological University</a>, supervised by <a href="https://liuziwei7.github.io/">Prof. Ziwei Liu</a>. Previously, I obtained my M.S. degree from School of Electrical and Electronic Engineering, Nanyang Technological University, and my B.Eng. degree from College of Automation, Harbin Engineering University.
                </p>
                <p>
                  My research interest lies in computer vision, deep learning and generative models. Currently I mainly focus on visual generation.
                </p>
                <p style="text-align:center">
                  <a href="mailto:tianxing001@e.ntu.edu.sg">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=CE8KY0MAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/_tianxing">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/TianxingWu/">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:35%;max-width:35%;">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%" alt="profile photo" src="images/me.jpg">
              </td>
            </tr>
          </tbody></table>

          <table style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul>
                <li>
                  [2024-08] One paper accepted to <a href="https://asia.siggraph.org/2024/">SIGGRAPH Asia 2024</a>.
                </li>
                <li>
                  [2024-07] One paper accepted to <a href="https://eccv2024.ecva.net/">ECCV 2024</a>.
                </li>
                <li>
                  [2024-02] Two papers accepted to <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a>.
                </li>
                <li>
                  [2024-01] One paper accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">TPAMI</a>.
                </li>
                <!-- <details>
                  <summary>Older News & Activities</summary>
                  <ul>
                    <li>
                      xxx
                    </li>
                  </ul>
                </details> -->
              </ul>
            </td>
            </tr>
          </tbody></table>
          

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle" colspan="2">
                <h2>Publications</h2>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/reversion.jpg' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://ziqihuangg.github.io/projects/reversion">
                  <span class="papertitle">ReVersion: Diffusion-Based Relation Inversion from Images</span>
                </a>
                <br>
                <a href="https://ziqihuangg.github.io/">Ziqi Huang*</a>, <strong>Tianxing Wu*</strong>, <a href="https://yumingj.github.io/">Yuming Jiang</a>, <a href="https://ckkelvinchan.github.io/">Kelvin C.K. Chan</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>SIGGRAPH Asia</em>, 2024
                <br>
                <a href="https://ziqihuangg.github.io/projects/reversion">project page</a>
                /
                <a href="https://arxiv.org/abs/2303.13495">arXiv</a>
                /
                <a href="https://www.youtube.com/watch?v=pkal3yjyyKQ">video</a>
                /
                <a href="https://github.com/ziqihuangg/ReVersion">code</a>
                <p></p>
                <p>Learn a relation prompt to capture co-existing relation in exemplar images, then apply to new entities for synthesizing new scenes.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/freeinit.gif' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://tianxingwu.github.io/pages/FreeInit/">
                  <span class="papertitle">FreeInit: Bridging Initialization Gap in Video Diffusion Models</span>
                </a>
                <br>
                <strong>Tianxing Wu</strong>, <a href="https://chenyangsi.github.io/">Chenyang Si</a>, <a href="https://yumingj.github.io/">Yuming Jiang</a>, <a href="https://ziqihuangg.github.io/">Ziqi Huang</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>ECCV</em>, 2024
                <br>
                <a href="https://tianxingwu.github.io/pages/FreeInit/">project page</a>
                /
                <a href="https://arxiv.org/abs/2312.07537">arXiv</a>
                /
                <a href="https://youtu.be/lS5IYbAqriI">video</a>
                /
                <a href="https://github.com/TianxingWu/FreeInit">code</a>
                <p></p>
                <p>We discover a training-inference gap in the noise initialization of video diffusion models, and propose FreeInit to bridge this gap. It improves temporal consistency and object appearance without training.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/videobooth.png' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://vchitect.github.io/VideoBooth-project/">
                  <span class="papertitle">VideoBooth: Diffusion-based Video Generation with Image Prompts</span>
                </a>
                <br>
                <a href="https://yumingj.github.io/">Yuming Jiang</a>, <strong>Tianxing Wu</strong>, <a href="https://williamyang1991.github.io/">Shuai Yang</a>, <a href="https://chenyangsi.github.io/">Chenyang Si</a>, <a href="http://dahua.site/">Dahua Lin</a>, <a href="https://scholar.google.com.sg/citations?user=gFtI-8QAAAAJ&hl=en">Yu Qiao</a>, <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>CVPR</em>, 2024
                <br>
                <a href="https://vchitect.github.io/VideoBooth-project/">project page</a>
                /
                <a href="https://arxiv.org/abs/2312.00777">arXiv</a>
                /
                <a href="https://youtu.be/10DxH1JETzI">video</a>
                /
                <a href="https://github.com/Vchitect/VideoBooth">code</a>
                <p></p>
                <p>A feed-forward framework for generating customized high-quality videos with subjects specified in image prompts.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/vbench.jpg' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://vchitect.github.io/VBench-project/">
                  <span class="papertitle">VBench: Comprehensive Benchmark Suite for Video Generative Models</span>
                </a>
                <br>
                <a href="https://ziqihuangg.github.io">Ziqi Huang*</a>,
                <a href="https://github.com/yinanhe">Yinan He*</a>,
                <a href="https://scholar.google.com/citations?user=iH0Aq0YAAAAJ&hl=zh-CN">Jiashuo Yu*</a>,
                <a href="https://github.com/zhangfan-p">Fan Zhang*</a>,
                <a href="https://chenyangsi.top/">Chenyang Si</a>,
                <a href="https://yumingj.github.io/">Yuming Jiang</a>,
                <a href="https://zhangyuanhan-ai.github.io/">Yuanhan Zhang</a>,
                <strong>Tianxing Wu</strong>,
                <a>Qingyang Jin</a>,
                <a href="https://nattapolchan.github.io/me">Nattapol Chanpaisit</a>,
                <a href="https://wyhsirius.github.io/">Yaohui Wang</a>,
                <a href="https://scholar.google.com/citations?user=3fWSC8YAAAAJ">Xinyuan Chen</a>,
                <a href="https://wanglimin.github.io">Limin Wang</a>,
                <a href="http://dahua.site/">Dahua Lin</a>,
                <a href="http://mmlab.siat.ac.cn/yuqiao/index.html">Yu Qiao</a>,
                <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>CVPR</em>, 2024 <font color="#ff6a5c"><strong>(Spotlight)</strong></font>
                <br>
                <a href="https://vchitect.github.io/VBench-project/">project page</a>
                /
                <a href="https://arxiv.org/abs/2311.17982">arXiv</a>
                /
                <a href="https://www.youtube.com/watch?v=7IhCC8Qqn8Y">video</a>
                /
                <a href="https://github.com/Vchitect/VBench">code</a>
                <p></p>
                <p>A comprehensive benchmark suite for video generative models.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/dgm4b.jpg' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://github.com/rshaojimmy/MultiModal-DeepFake">
                  <span class="papertitle">Detecting and Grounding Multi-Modal Media Manipulation and Beyond</span>
                </a>
                <br>
                <a href="https://rshaojimmy.github.io/">Rui Shao</a>, <strong>Tianxing Wu</strong>, <a href="https://jlwu1992.github.io/">Jianlong Wu</a>, <a href="https://liqiangnie.github.io/index.html">Liqiang Nie</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>TPAMI</em>, 2024
                <br>
                <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">project page</a>
                /
                <a href="https://arxiv.org/abs/2309.14203">arXiv</a>
                /
                <a href="https://github.com/rshaojimmy/MultiModal-DeepFake">code</a>
                <p></p>
                <p> We propose HAMMER++ to better tackle the DGM4 challenge.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/talk-to-edit-pami.png' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://www.mmlab-ntu.com/project/talkedit/">
                  <span class="papertitle">Talk-to-Edit: Fine-Grained 2D and 3D Facial Editing via Dialog</span>
                </a>
                <br>
                <a href="https://yumingj.github.io/">Yuming Jiang</a>, <a href="https://ziqihuangg.github.io/">Ziqi Huang</a>, <strong>Tianxing Wu</strong>, <a href="https://xingangpan.github.io/">Xingang Pan</a>, <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>TPAMI</em>, 2023
                <br>
                <a href="https://www.mmlab-ntu.com/project/talkedit/">project page</a>
                /
                <a href="data/2023_tpami_talk_to_edit_3d.pdf">pdf</a>
                /
                <a href="https://ieeexplore.ieee.org/document/10374263/">paper</a>
                <p></p>
                <p> An interactive 2D + 3D facial editing framework that performs fine-grained attribute manipulation through dialog between the user and the system.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/dgm4.png' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">
                  <span class="papertitle">Detecting and Grounding Multi-Modal Media Manipulation</span>
                </a>
                <br>
                <a href="https://rshaojimmy.github.io/">Rui Shao</a>, <strong>Tianxing Wu</strong>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>CVPR</em>, 2023
                <br>
                <a href="https://rshaojimmy.github.io/Projects/MultiModal-DeepFake">project page</a>
                /
                <a href="https://arxiv.org/abs/2304.02556">arXiv</a>
                /
                <a href="https://youtu.be/EortO0cqnGE">video</a>
                /
                <a href="https://github.com/rshaojimmy/MultiModal-DeepFake">code</a>
                <p></p>
                <p>Different from existing forgery detection tasks, DGM4 performs real/fake classification on image-text pairs, and further attempts to detect fine-grained manipulation types and ground manipulated image bboxes and text tokens.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/seqfakeformer.png' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://rshaojimmy.github.io/Projects/SeqDeepFake">
                  <span class="papertitle">SeqDeepFake: Detecting and Recovering Sequential DeepFake Manipulation</span>
                </a>
                <br>
                <a href="https://rshaojimmy.github.io/">Rui Shao</a>, <strong>Tianxing Wu</strong>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>ECCV</em>, 2022
                <br>
                <a href="https://rshaojimmy.github.io/Projects/SeqDeepFake">project page</a>
                /
                <a href="https://arxiv.org/abs/2207.02204">arXiv</a>
                /
                <a href="https://github.com/rshaojimmy/SeqDeepFake">code</a>
                <p></p>
                <p>In this work, we focus on detecting DeepFake manipulation sequences rather than binary lables.</p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle" colspan="2">
                <h2>Pre-prints</h2>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/lavie.gif' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://vchitect.github.io/LaVie-project/">
                  <span class="papertitle">LaVie: High-Quality Video Generation with Cascaded Latent Diffusion Models</span>
                </a>
                <br>
                  <a href="https://wyhsirius.github.io/">Yaohui Wang*</a>, 
                  <a href="https://scholar.google.com/citations?user=3fWSC8YAAAAJ">Xinyuan Chen*</a>, 
                  <a href="https://maxin-cn.github.io/">Xin Ma*</a>, 
                  <a href="https://shangchenzhou.com/">Shangchen Zhou</a>, 
                  <a href="https://ziqihuangg.github.io/">Ziqi Huang</a>, 
                  <a href="https://shepnerd.github.io/">Yi Wang</a>, 
                  <a href="https://ceyuan.me/">Ceyuan Yang</a>, 
                  <a href="https://github.com/yinanhe">Yinan He</a>, 
                  <a href="https://scholar.google.com/citations?user=iH0Aq0YAAAAJ&hl=en">Jiashuo Yu</a>, 
                  <a href="https://pq-yang.github.io/">Peiqing Yang</a>, 
                  <a href="https://github.com/guoyww">Yuwei Guo</a>, 
                  <strong>Tianxing Wu</strong>, 
                  <a href="http://chenyangsi.top/">Chenyang Si</a>, 
                  <a href="https://yumingj.github.io/">Yuming Jiang</a>, 
                  <a href="https://cunjian.github.io/">Cunjian Chen</a>, 
                  <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>, 
                  <a href="https://daibo.info/">Bo Dai</a>, 
                  <a href="http://dahua.site/">Dahua Lin</a>, 
                  <a href="https://scholar.google.com.hk/citations?user=gFtI-8QAAAAJ&hl=zh-CN">Yu Qiao</a>, 
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>arXiv</em>, 2023
                <br>
                <a href="https://vchitect.github.io/LaVie-project/">project page</a>
                /
                <a href="https://arxiv.org/abs/2309.15103">arXiv</a>
                /
                <a href="https://github.com/Vchitect/LaVie">code</a>
                <p></p>
                <p>An integrated video generation framework that operates on cascaded video latent diffusion models, comprising a base T2V model, a temporal interpolation model, and a video super-resolution model.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/deepfake-adapter.jpg' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://github.com/rshaojimmy/DeepFake-Adapter">
                  <span class="papertitle">DeepFake-Adapter: Dual-Level Adapter for DeepFake Detection</span>
                </a>
                <br>
                <a href="https://rshaojimmy.github.io/">Rui Shao</a>, <strong>Tianxing Wu</strong>, <a href="https://liqiangnie.github.io/index.html">Liqiang Nie</a>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>arXiv</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2306.00863">arXiv</a>
                /
                <a href="https://github.com/rshaojimmy/DeepFake-Adapter">code</a>
                <p></p>
                <p>A dual-level adapter that adapts a pre-trained ViT for generalizable deepfake detection.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:20%;vertical-align:middle">
                <img src='images/seqfakeformer-ext.jpg' width="240">
              </td>
              <td style="padding:20px;width:80%;vertical-align:middle">
                <a href="https://github.com/rshaojimmy/SeqDeepFake">
                  <span class="papertitle">Robust Sequential DeepFake Detection</span>
                </a>
                <br>
                <a href="https://rshaojimmy.github.io/">Rui Shao</a>, <strong>Tianxing Wu</strong>, <a href="https://liuziwei7.github.io/">Ziwei Liu</a>
                <br>
                <em>arXiv</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2309.14991">arXiv</a>
                /
                <a href="https://github.com/rshaojimmy/SeqDeepFake">code</a>
                <p></p>
                <p>Building stronger correspondence between image-sequence pairs for more robust Seq-DeepFake detection.</p>
              </td>
            </tr>
          </tbody></table>

          <table style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle">
              <h2>Academic Services</h2>
              <ul>
                <li>
                  Conference Reviewer: CVPR'23/24, ICCV'23, ECCV'24, NeurIPS'22/23/24, ICLR'23, SIGGRAPH Asia'24, WACV'23
                </li>
                <li>
                  Journal Reviewer: IJCV, IET-CV
                </li>
              </ul>
            </td>
            </tr>
          </tbody></table>

          <table style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle">
              <h2>Teaching</h2>
              <ul>
                <li>
                  Teaching Assistant: SC2001/CE2101/CZ2101 Algorithm Design & Analysis, NTU, 2024 Spring
                </li>
              </ul>
            </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Source code origin: <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a> 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
